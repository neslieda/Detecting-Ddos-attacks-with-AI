{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9QBM2cEBoSf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import roc_curve\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPX6nWqGBp0-",
        "outputId": "71a4d16a-28ca-49dd-8d86-cf10dc7bfc4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Benign: 0\n",
            "Anomaly: 1\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data1=pd.read_csv('/content/drive/MyDrive/dosdata/data1.csv')\n",
        "data2=pd.read_csv('/content/drive/MyDrive/dosdata/data2.csv')\n",
        "data3=pd.read_csv('/content/drive/MyDrive/dosdata/data3.csv')\n",
        "\n",
        "train_data=pd.concat([data1,data2,data3]).reset_index(drop=True)\n",
        "\n",
        "train_data = train_data.drop(columns='Unnamed: 0')\n",
        "\n",
        "train_data[\"Label\"] = train_data[\"Label\"].replace([\"Benign\",\"Anomaly\"],[0,1])\n",
        "for label, index in zip(['Benign', 'Anomaly'], [0, 1]):\n",
        "    print(f\"{label}: {index}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZjm99FHBp4Y",
        "outputId": "1355cbcd-4b92-48c8-e634-7f328a8eefa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "0    1567950\n",
            "1    1000448\n",
            "Name: count, dtype: int64\n",
            "Counter({0: 1000448, 1: 1000448})\n"
          ]
        }
      ],
      "source": [
        "print(train_data[\"Label\"].value_counts())\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from collections import Counter\n",
        "\n",
        "X = train_data.drop(\"Label\", axis=1)\n",
        "y = train_data[\"Label\"]\n",
        "\n",
        "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
        "X, y = undersample.fit_resample(X, y)\n",
        "\n",
        "print(Counter(y))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def evaluate_fold_performance(estimator, X, y, fold_idx, fold):\n",
        "\n",
        "    train_idx, val_idx = fold\n",
        "    X_fold_train, X_fold_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "    y_fold_train, y_fold_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_fold_train = scaler.fit_transform(X_fold_train)\n",
        "    X_fold_val = scaler.transform(X_fold_val)\n",
        "\n",
        "    estimator.fit(X_fold_train, y_fold_train)\n",
        "    y_pred = estimator.predict(X_fold_val)\n",
        "    y_pred_proba = estimator.predict_proba(X_fold_val)[:, 1]\n",
        "\n",
        "    metrics = {\n",
        "        'fold': fold_idx + 1,\n",
        "        'accuracy': accuracy_score(y_fold_val, y_pred),\n",
        "        'precision': precision_score(y_fold_val, y_pred),\n",
        "        'recall': recall_score(y_fold_val, y_pred),\n",
        "        'f1': f1_score(y_fold_val, y_pred),\n",
        "        'auc_roc': roc_auc_score(y_fold_val, y_pred_proba)\n",
        "    }\n",
        "\n",
        "    cm = confusion_matrix(y_fold_val, y_pred)\n",
        "    metrics['tn'], metrics['fp'], metrics['fn'], metrics['tp'] = cm.ravel()\n",
        "\n",
        "    return metrics, y_pred_proba, y_fold_val\n",
        "\n",
        "def optimize_svm_detailed(X, y, cv=5):\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
        "\n",
        "    # Parametre aralıklarını küçülttük\n",
        "    svm_kernels = {\n",
        "        'linear': (SVC(probability=True), {\n",
        "            'C': [0.1, 1],\n",
        "        }),\n",
        "        'rbf': (SVC(probability=True), {\n",
        "            'C': [1],\n",
        "            'gamma': ['scale', 0.1],\n",
        "        }),\n",
        "        'poly': (SVC(probability=True), {\n",
        "            'C': [1],\n",
        "            'degree': [2, 3],\n",
        "            'gamma': ['scale'],\n",
        "        })\n",
        "    }\n",
        "\n",
        "    best_results = {}\n",
        "    all_metrics = []\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "    for kernel_type, (classifier, param_grid) in svm_kernels.items():\n",
        "        print(f\"\\n{'-'*50}\")\n",
        "        print(f\"Evaluating SVM with {kernel_type} kernel...\")\n",
        "\n",
        "        grid_search = GridSearchCV(\n",
        "            estimator=classifier,\n",
        "            param_grid=param_grid,\n",
        "            cv=skf,\n",
        "            scoring='accuracy',\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        grid_search.fit(X_scaled, y)\n",
        "\n",
        "        print(f\"\\nBest Parameters for {kernel_type}:\", grid_search.best_params_)\n",
        "        print(f\"Best Cross-Validation Score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "        best_model = grid_search.best_estimator_\n",
        "        fold_metrics = []\n",
        "        fold_predictions = []\n",
        "        fold_true_values = []\n",
        "\n",
        "        for fold_idx, fold in enumerate(skf.split(X_scaled, y)):\n",
        "            metrics, y_pred_proba, y_true = evaluate_fold_performance(\n",
        "                best_model, X_scaled, y, fold_idx, fold\n",
        "            )\n",
        "            metrics['kernel_type'] = kernel_type\n",
        "            fold_metrics.append(metrics)\n",
        "            fold_predictions.append(y_pred_proba)\n",
        "            fold_true_values.append(y_true)\n",
        "\n",
        "            print(f\"\\nFold {fold_idx + 1} Metrics:\")\n",
        "            print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
        "            print(f\"Precision: {metrics['precision']:.4f}\")\n",
        "            print(f\"Recall: {metrics['recall']:.4f}\")\n",
        "            print(f\"F1-Score: {metrics['f1']:.4f}\")\n",
        "            print(f\"AUC-ROC: {metrics['auc_roc']:.4f}\")\n",
        "            print(\"\\nConfusion Matrix:\")\n",
        "            print(f\"TN: {metrics['tn']}, FP: {metrics['fp']}\")\n",
        "            print(f\"FN: {metrics['fn']}, TP: {metrics['tp']}\")\n",
        "\n",
        "        all_metrics.extend(fold_metrics)\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        for fold_idx in range(cv):\n",
        "            fpr, tpr, _ = roc_curve(\n",
        "                fold_true_values[fold_idx],\n",
        "                fold_predictions[fold_idx]\n",
        "            )\n",
        "            plt.plot(\n",
        "                fpr, tpr,\n",
        "                label=f'Fold {fold_idx + 1} (AUC = {fold_metrics[fold_idx][\"auc_roc\"]:.4f})'\n",
        "            )\n",
        "\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title(f'ROC Curves for SVM with {kernel_type} kernel (All Folds)')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "        best_results[kernel_type] = {\n",
        "            'model': best_model,\n",
        "            'params': grid_search.best_params_,\n",
        "            'score': grid_search.best_score_\n",
        "        }\n",
        "\n",
        "    metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "    print(\"\\nAverage Metrics by Kernel Type:\")\n",
        "    avg_metrics = metrics_df.groupby('kernel_type').agg({\n",
        "        'accuracy': ['mean', 'std'],\n",
        "        'precision': ['mean', 'std'],\n",
        "        'recall': ['mean', 'std'],\n",
        "        'f1': ['mean', 'std'],\n",
        "        'auc_roc': ['mean', 'std']\n",
        "    })\n",
        "    print(avg_metrics)\n",
        "\n",
        "    best_kernel_type = max(best_results.items(), key=lambda x: x[1]['score'])[0]\n",
        "    best_model = best_results[best_kernel_type]['model']\n",
        "\n",
        "    print(f\"\\nBest performing kernel: {best_kernel_type}\")\n",
        "    print(f\"Best parameters: {best_results[best_kernel_type]['params']}\")\n",
        "\n",
        "    return best_model, best_results, metrics_df"
      ],
      "metadata": {
        "id": "ceexAt21m_zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYXv-RMpigfW"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7-H6lkHikZB",
        "outputId": "48674b8d-198f-4d42-d88b-d2842d12a05e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "Evaluating SVM with linear kernel...\n",
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
          ]
        }
      ],
      "source": [
        "best_model, best_results, metrics_df = optimize_svm_detailed(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfWVKo15ioQb"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_test_scaled = scaler.fit_transform(X_test)\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "print(\"\\nFinal Test Set Performance:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix on Test Set')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEsDhB01z6IH",
        "outputId": "df3bfda1-5aa3-43d9-dfe0-fbac703bec20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def evaluate_fold_performance_svm(estimator, X, y, fold_idx, fold):\n",
        "    \"\"\"\n",
        "    Evaluate model performance for a single fold in SVM.\n",
        "    \"\"\"\n",
        "    train_idx, val_idx = fold\n",
        "    X_fold_train, X_fold_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "    y_fold_train, y_fold_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_fold_train = scaler.fit_transform(X_fold_train)\n",
        "    X_fold_val = scaler.transform(X_fold_val)\n",
        "\n",
        "    estimator.fit(X_fold_train, y_fold_train)\n",
        "    y_pred = estimator.predict(X_fold_val)\n",
        "    y_pred_proba = estimator.decision_function(X_fold_val)\n",
        "\n",
        "    metrics = {\n",
        "        'fold': fold_idx + 1,\n",
        "        'accuracy': accuracy_score(y_fold_val, y_pred),\n",
        "        'precision': precision_score(y_fold_val, y_pred),\n",
        "        'recall': recall_score(y_fold_val, y_pred),\n",
        "        'f1': f1_score(y_fold_val, y_pred),\n",
        "        'auc_roc': roc_auc_score(y_fold_val, y_pred_proba)\n",
        "    }\n",
        "\n",
        "    cm = confusion_matrix(y_fold_val, y_pred)\n",
        "    metrics['tn'], metrics['fp'], metrics['fn'], metrics['tp'] = cm.ravel()\n",
        "\n",
        "    return metrics, y_pred_proba, y_fold_val\n",
        "\n",
        "def optimize_svm_detailed(X, y, cv=5):\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
        "\n",
        "    svm = SVC(probability=True)\n",
        "    param_grid = {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf', 'poly'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    }\n",
        "\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=svm,\n",
        "        param_grid=param_grid,\n",
        "        cv=skf,\n",
        "        scoring='accuracy',\n",
        "        n_jobs=-1,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "    grid_search.fit(X_scaled, y)\n",
        "\n",
        "    print(\"\\nBest Parameters for SVM:\", grid_search.best_params_)\n",
        "    print(f\"Best Cross-Validation Score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "    best_model = grid_search.best_estimator_\n",
        "    fold_metrics = []\n",
        "    fold_predictions = []\n",
        "    fold_true_values = []\n",
        "\n",
        "    for fold_idx, fold in enumerate(skf.split(X_scaled, y)):\n",
        "        metrics, y_pred_proba, y_true = evaluate_fold_performance_svm(\n",
        "            best_model, X_scaled, y, fold_idx, fold\n",
        "        )\n",
        "        fold_metrics.append(metrics)\n",
        "        fold_predictions.append(y_pred_proba)\n",
        "        fold_true_values.append(y_true)\n",
        "\n",
        "        print(f\"\\nFold {fold_idx + 1} Metrics:\")\n",
        "        print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
        "        print(f\"Precision: {metrics['precision']:.4f}\")\n",
        "        print(f\"Recall: {metrics['recall']:.4f}\")\n",
        "        print(f\"F1-Score: {metrics['f1']:.4f}\")\n",
        "        print(f\"AUC-ROC: {metrics['auc_roc']:.4f}\")\n",
        "        print(\"\\nConfusion Matrix:\")\n",
        "        print(f\"TN: {metrics['tn']}, FP: {metrics['fp']}\")\n",
        "        print(f\"FN: {metrics['fn']}, TP: {metrics['tp']}\")\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    for fold_idx in range(cv):\n",
        "        fpr, tpr, _ = roc_curve(\n",
        "            fold_true_values[fold_idx],\n",
        "            fold_predictions[fold_idx]\n",
        "        )\n",
        "        plt.plot(\n",
        "            fpr, tpr,\n",
        "            label=f'Fold {fold_idx + 1} (AUC = {fold_metrics[fold_idx][\"auc_roc\"]:.4f})'\n",
        "        )\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curves for SVM (All Folds)')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    metrics_df = pd.DataFrame(fold_metrics)\n",
        "\n",
        "    print(\"\\nAverage Metrics for SVM:\")\n",
        "    avg_metrics = metrics_df.agg({\n",
        "        'accuracy': ['mean', 'std'],\n",
        "        'precision': ['mean', 'std'],\n",
        "        'recall': ['mean', 'std'],\n",
        "        'f1': ['mean', 'std'],\n",
        "        'auc_roc': ['mean', 'std']\n",
        "    })\n",
        "    print(avg_metrics)\n",
        "\n",
        "    return best_model, metrics_df\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "best_model, metrics_df = optimize_svm_detailed(X_train, y_train)\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(\"\\nFinal Test Set Performance:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix on Test Set')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKd0mGAoBaP5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "def optimize_svm(X, y, cv=5):\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
        "\n",
        "    param_grid = {\n",
        "        'C': [0.1, 1, 10, 100],\n",
        "        'gamma': ['scale', 'auto'],\n",
        "        'kernel': ['rbf', 'linear', 'poly', 'sigmoid']\n",
        "    }\n",
        "\n",
        "    svm = SVC(random_state=42)\n",
        "\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=svm,\n",
        "        param_grid=param_grid,\n",
        "        cv=skf,\n",
        "        scoring='accuracy',\n",
        "        n_jobs=-1,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    grid_search.fit(X, y)\n",
        "\n",
        "    print(\"Best Parameters:\", grid_search.best_params_)\n",
        "    print(\"Best Cross-Validation Score:\", grid_search.best_score_)\n",
        "\n",
        "    cv_results = pd.DataFrame(grid_search.cv_results_)\n",
        "    cv_results = cv_results[['params', 'mean_test_score', 'std_test_score']]\n",
        "    cv_results = cv_results.sort_values('mean_test_score', ascending=False).head()\n",
        "\n",
        "    return grid_search.best_estimator_, cv_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZUweh45B5w_"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEsAIEARB73G"
      },
      "outputs": [],
      "source": [
        "best_model, cv_results = optimize_svm(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZimSMNATB76B"
      },
      "outputs": [],
      "source": [
        "print(\"\\nTop 5 model performance:\")\n",
        "print(cv_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbVbXmYhB78e"
      },
      "outputs": [],
      "source": [
        "y_pred = best_model.predict(X_test)\n",
        "print(\"\\nTest set performance metrics:\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}